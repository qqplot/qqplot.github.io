---
layout: post
title:  "데이터 파이프라인에 대한 생각"
author: qqplot
categories: [ MachineLearning ]
image: assets/images/15.jpg
beforetoc: "IT 용어는 알쏭달쏭하다. 대부분 마케팅 용어라고 생각한다. 구현하는 방법은 달라도 하고자 하는 로직 자체는 간단하다."
toc: true
---







### 데이터 파이프라인이란

데이터를 소비자에게 전달하는 일련의 프로세스를 의미한다. 



[데이터웨어하우스(DW)란]: https://brunch.co.kr/@qqplot/46



데이터웨어하우스에 대한 이야기를 썼었다. 사실 딱 잘라서 구분하기 애매한 용어들이라고 생각한다. 데이터 파이프라인은 웨어하우스까지 들어오는 부분이라고 봐도 무방하다. 기존 용어로는 ETL이라고도 하는데 그것과 구분하기 위해서 데이터 파이프라인이라는 용어가 생겼다고 본다. 하는 일 자체는 동일하다 A라는 곳에 있는 데이터를 B라는 곳으로 옮긴다. 이것을 하고 싶은 것이다. 다만 ETL은 운영계나 기존 시스템의 RDB에서 가져오는 다소 정적인 부분을 수행하는 것을 칭한다면 데이터 파이프라인은 비정형 데이터, 대용량 데이터 등은



이에 대해 그림 등으로 친절하게 설명된 링크를 참조한다.



https://rk1993.tistory.com/entry/pipeline%EC%9D%B4%EB%9E%80





데이터를 수집하고 가공하여 소비자에게 전달하는 것이다.



안정적인 실시간 이벤트 처리

일별 평균 40~50억 건의 실시간 이벤트 처리

10초 안에 데이터파이프라인의 아웃풋을 생성





데이터 분석을 통해 생성도니 부가 정보들(메타)을 안정적으로 저장, 관리하고 실시간 이벤트와 조인

이벤트별로 조인해놔야 하는 메타들이 2~3개 정도

일간 업데이트가 필요한 부가 정보 데이터 종류만 해도 갯수가 70여개



여러 데이터 소스를 수용할 수 있을 정도로 일반화 되고 스케일러블한 저장소 필요

단순 실시간으로 저장되는 이벤트를 모두 한달만 저장한다고 해도 50억 * 30 = 1500억개

매일 매일 업데이트 되는 부가 정보 데이터들은 하루에 500억개

6개월치를 저장한다고 치면?

여러 개의 서비스에서 발생하는 사용자 데이터가 하나의 스토리지에 저장되어야 함으로

스토리지의 효율성과 성능이 중요함





최종적으로 저장된 데이터에 여러 서비스에 unified, scalable한 공통된 API를 제공해야 함

쓸만 하다 싶으면 갑자기 연동을 원하는 서비스 수가 급증









### 데이터 파이프라인를 만들면 좋은 점



Data Pipeline 을 구축해서 얻는 이득들

\- 모든 서비스가 일반화된 abstract layer(Property Graph Model)를 이해하고, 일반화된 API(Graph Query)에 익숙해지면, 서비스 요청마다 API서버를 구축할 필요가 없음.

 아직까지는 getEdjes, getVertices 두 개의 API만으로 모든 서비스의 요구조건을 처리

 모두가 Vertex, Edge이고, 모두가 getEdges, getVertices.

\- 사내 부서마다 하둡, 카프카 클러스터, 스파크, HBase 등을 따로 운영하면, 운영 Cost가 너무 큼. 대부분의 오픈소스가 scalable한 아키텍쳐를 가지므로, 이 오픈소스들을 사용해 multi-tenancy를 어떻게 제공할지 고민을 하는 게 더 효율적임

\- 여러 팀에 혼재되어 있는 분석된 결과를 서비스에 적용하기 쉽게 하여 더 많은 실험(삽질)을 할 수 있게 비용을 낮춰줌

\- A/B테스트 및 데이터에 기반한 의사결정에도 기여



= 개발 편의성 + 빠른 데이터 처리 + 운영비용 절감 + 중복 코드작업 제거 + 데이터 기반 의사결정





### 아키텍쳐

수집 -> 가공 -> 저장 및 API 제공



\1. 데이터 수집

기술적으로는 난이도보다는 복잡함이 더 크다

공통된 포멧을 정의하고 공통으로 사용할 END POINT를 만드는 일이 필수

수집이 안되면 가공 아무리 잘해도 안됨



1. 수집 Layer 문제 정의

클라이언트 자바 스크립트  log_event



각각의 서비스에서 데이터 파이프라인에 REST API를 통해 데이터를 ingest

두 가지로 input의 성격을 분류

a. Synchronous: ingest 요청의 응답이 실제로 Storage에 Persist된 이후에 돌아가야 함.

보통 관계에 대한 데이터일 경우들이 많음

b. Asynchronous: ingest 요청에 응답을 바로 주고, 어싱크로나우스하게 이벤트가 persist됨





\2. 가공

데이터 마이닝, 러신머닝, 데이터사이언스 등등 팬시한 분야

가공만 아무리 잘해봐야 소용없음



\3. 저장 및 API제공

가공된 데이터를 서비스에서 가져다 사용할 수 있는 PRODUCT 형태로 저장하고 API를 제공

중요도에 비해 ADHOC하게 진행되는 경우가 많음

**애드혹**([라틴어](https://ko.wikipedia.org/wiki/라틴어): Ad hoc 아드 혹[[*](https://ko.wikipedia.org/wiki/위키백과:외래어_표기법/라틴어_표기_원칙)])은 "이것을 위해" 즉 "특별한 목적을 위해서"라는 뜻의 [라틴어](https://ko.wikipedia.org/wiki/라틴어)로, 일반적으로 다음을 나타낸다.  

특정한 문제나 일을 위해 만들어진 관습적인 해결책

일반화할 수 없는 해결책

어떤 다른 목적에 적응시킬 수 없는 해결책



### 데이터를 다루는 것은 노가다

오픈 소스의 이해를 기반으로 한 데이터 흐름 아키텍쳐

오픈소스들이 아무리 좋다고 내가 필요한, 내 서비스에 사용자들이 필요한 데이터들이 갑자기 나타나는 건 아님

필요한 데이터를 정의하고 이를 서비스에 적용하는 iteration의 반복이 실제 일( 개발<<< 노가다)





개별 서비스의 할 일 줄여주기

데이터 타입 및 포맷 정의

데이터 수집 End point???? 제공 및 가이드, 운영



데이터 수집, 저장, API에 대한 명확한 스펙

어떤 데이터가 아웃풋으로 나오고 이를 어떻게 가져다 어디에 사용할 수 있는지 모두의 이해와 협조가 필요함

이해와 협조를 위해서는 명확한 스펙이 필수(공감)



서비스의 퀄리티를 지속적으로 높이기

데이터비즈니스는 로직 실험 설꼐 -> 서비스 적용 -> AB테스트 -> 성과 측정 -> 로직 실험 설계의 끊임없는 Iteration. 

Iteration 플랫폼이 있어도 실무진의 인식 변화에는 많은 노력과 시간이 듦

Data >> Opinion









### 결국은 문화

무조건 RAW 데이터를 내놓으시오.

서비스에서 Operation을 설명하고 가공된 결과를 가져가면 서로 

서비스에서 operation을 설명하고 가공된 결과를 가져가면 서로 편한데 무조건 원본 데이터를 요구

서비스별로 kafka 설치하고, spark 설치하고 이 모두가 낭비라는 걸 관철





뭐 기술은 어려울 건 없네

카프카가 좋다는데 카프카나 써볼까?

실제로 Platform 자체는 구성에 큰 어려움 없음(여러 오픈소스들을 요령껏 사용, 안되면 만들면 됨)





제일 어려운 부분은 서비스에서 필요한 데이터는 무엇일까?

서비스에서 더 편리하게 사용할 수 있는 Input/Output format은 무엇일까?

이벤트들에 어떤 데이터들을 조인해놓으면 어떤 뷰를 완성할 수 있는지 끊임 없는 삽질



서비스에 영업

회사 분위기가 사내 솔루션이 호의적인 회사는 아님. 무려 듣보잡 오픈 소스들이네?

제공할 수 있는 데이터 프로덕트/API가 명확하지 않은 게 문제.

데이터는 왜 모으냐?

너네 팀 데이터도 아닌데 왜 보려하느냐?

우리한테 뭐가 이득이ㅑㄴ?













